{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMu+MoBY/hrpvgaI1psz6HB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmTampz/Copra_YOLOv11_v12_Colab_Notebooks/blob/main/Copra_1_manual_optimized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgHH8hftgVWy",
        "outputId": "bc1c69e4-7b76-4224-86d1-d75c5cd4e12f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.224)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.9)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.12/dist-packages (1.2.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.10.5)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Requirement already satisfied: pi-heif<2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.1.1)\n",
            "Requirement already satisfied: pillow-avif-plugin<2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.60.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.4)\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# üì¶ ENVIRONMENT SETUP for YOLOv11 Thesis (Colab)\n",
        "\n",
        "# Core deep learning and YOLO library\n",
        "!pip install -U ultralytics\n",
        "\n",
        "# Core data handling, visualization, and ML utilities\n",
        "!pip install pandas matplotlib seaborn pillow scikit-learn\n",
        "\n",
        "#local dashboard:  monitoring and logging\n",
        "!pip install tensorboard tqdm\n",
        "\n",
        "# Roboflow integration\n",
        "!pip install roboflow\n",
        "\n",
        "# cloud-connected research tracker\n",
        "!pip -q install wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, ultralytics, pandas as pd, matplotlib, seaborn, PIL, sklearn, tqdm, tensorboard\n",
        "\n",
        "print(f\"PyTorch version : {torch.__version__}\")\n",
        "print(f\"CUDA available  : {torch.cuda.is_available()}\")\n",
        "print(f\"Ultralytics ver : {ultralytics.__version__}\")\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEYK9F_5ktKg",
        "outputId": "5ddf351e-c5fd-43d3-ad8e-ae89c7bb752d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.224 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 40.2/235.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "manual_tuning_yolo11.py\n",
        "Manual hyperparameter tuning for YOLOv11 (Detection -> Segmentation -> Classification)\n",
        "Integrated with Roboflow API for automatic dataset download (YOLO format).\n",
        "\n",
        "Now includes robust interruption safety:\n",
        "üîí Checkpointing every N epochs (save_period)\n",
        "üîÅ Auto-resume from latest checkpoint (Ultralytics resume + W&B resume)\n",
        "üíæ Saves everything to Google Drive for persistence\n",
        "üìä Weights & Biases (W&B) logging to the cloud (resumable, descriptive run names)\n",
        "\n",
        "Still includes:\n",
        "‚úÖ Per-class PR curves (AUC/AP) + combined plot (detection-style)\n",
        "‚úÖ Per-class Precision, Recall, F1, Accuracy (Macro & Weighted)\n",
        "‚úÖ Confusion matrix + overall accuracy\n",
        "‚úÖ CSV + PNG per run, limited inference previews\n",
        "‚úÖ One-click ZIP of all artifacts for download\n",
        "‚úÖ TensorBoard logs (optional)\n",
        "\n",
        "Run first (in another Colab cell):\n",
        "!pip install ultralytics roboflow pandas matplotlib seaborn pillow scikit-learn wandb\n",
        "\"\"\"\n",
        "import os, time, shutil, yaml, json, random, glob, zipfile, hashlib\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    precision_recall_fscore_support,\n",
        "    accuracy_score,\n",
        ")\n",
        "\n",
        "# ---------------- W&B Auto Login (No Prompt Needed) ----------------\n",
        "os.environ[\"WANDB_API_KEY\"] = \"02a2986eed98555093c4c2920a04c631a89430cc\"\n",
        "!wandb login $WANDB_API_KEY --relogin\n",
        "\n",
        "import wandb\n",
        "print(\"Current W&B status:\", wandb.api.api_key)\n",
        "\n",
        "# ---------------- Google Drive Persistence ----------------\n",
        "# üíæ Mount Google Drive so all checkpoints/logs survive Colab disconnections\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount('/content/drive')\n",
        "    DRIVE_OK = True\n",
        "except Exception:\n",
        "    DRIVE_OK = False\n",
        "\n",
        "# If Drive is mounted, results will be stored persistently in MyDrive\n",
        "PERSIST_BASE = \"/content/drive/MyDrive/yolo_copra\" if DRIVE_OK else \"/content\"\n",
        "RESULTS_BASE = os.path.join(PERSIST_BASE, \"copra_yolo11_manual_results\")\n",
        "os.makedirs(RESULTS_BASE, exist_ok=True)\n",
        "\n",
        "# ---------------- Roboflow Dataset Integration ----------------\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"LS1Ohi2OQZ178OOqQ4zc\")              # <-- API_KEY\n",
        "project = rf.workspace(\"cv-opfhv\").project(\"mor-v4-8itha\")  # <-- project slug\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov11\")\n",
        "\n",
        "ROBOFLOW_DATA_YAML = os.path.join(dataset.location, \"data.yaml\")\n",
        "print(f\"‚úÖ Dataset downloaded successfully!\\nüìÇ YAML: {ROBOFLOW_DATA_YAML}\")\n",
        "\n",
        "# ---------------- YOLOv11 + Logging Configurations ----------------\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Image as IPyImage, display\n",
        "\n",
        "TENSORBOARD_ENABLE = True      # for local visualization\n",
        "WANDB_ENABLE = True            # enable W&B logging\n",
        "WANDB_PROJECT = \"Copra-YOLOv11-Tuning\"  # Descriptive W&B project name\n",
        "\n",
        "# ---------------- TensorBoard + W&B Helpers ----------------\n",
        "def ensure_tensorboard():\n",
        "    \"\"\"Enable Ultralytics TensorBoard logging.\"\"\"\n",
        "    if TENSORBOARD_ENABLE:\n",
        "        os.system(\"yolo settings tensorboard=True\")\n",
        "\n",
        "def ensure_wandb():\n",
        "    \"\"\"Enable W&B logging for cloud-based tracking and resumption.\"\"\"\n",
        "    if not WANDB_ENABLE:\n",
        "        os.system(\"yolo settings wandb=False\")\n",
        "        return None, None\n",
        "    os.system(\"yolo settings wandb=True\")\n",
        "    import wandb\n",
        "    return wandb, True\n",
        "\n",
        "# ---------------- Task and Hyperparameter Setup ----------------\n",
        "TASKS = [\"detect\", \"seg\", \"cls\"]\n",
        "MODEL_MAP = {\n",
        "    \"detect\": \"yolo11n.pt\",\n",
        "    \"seg\":    \"yolo11n-seg.pt\",\n",
        "}\n",
        "\n",
        "MANUAL_CONFIG = {\n",
        "    \"epochs\": 100,\n",
        "    \"batch\": 16,\n",
        "    \"optimizer\": \"auto\",\n",
        "    \"lr0\": 0.001,\n",
        "    \"patience\": 100,\n",
        "    \"save_period\": 5   # Save checkpoint every N epochs\n",
        "}\n",
        "\n",
        "IMG_SIZE = 640\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "SUMMARY_CSV = os.path.join(RESULTS_BASE, f\"manual_summary_{TIMESTAMP}.csv\")\n",
        "\n",
        "# ---------------- Utility Functions ----------------\n",
        "def load_data_yaml(path):\n",
        "    \"\"\"Load dataset metadata (class names, paths) from YAML.\"\"\"\n",
        "    with open(path, \"r\") as f:\n",
        "        return yaml.safe_load(f)\n",
        "\n",
        "def iou_xyxy(box1, box2):\n",
        "    \"\"\"Compute IoU between two [x1,y1,x2,y2] boxes.\"\"\"\n",
        "    x1 = max(box1[0], box2[0]); y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2]); y2 = min(box1[3], box2[3])\n",
        "    inter_w, inter_h = max(0, x2 - x1), max(0, y2 - y1)\n",
        "    inter_area = inter_w * inter_h\n",
        "    area1 = (box1[2]-box1[0])*(box1[3]-box1[1])\n",
        "    area2 = (box2[2]-box2[0])*(box2[3]-box2[1])\n",
        "    union = area1 + area2 - inter_area\n",
        "    return inter_area / union if union > 0 else 0.0\n",
        "\n",
        "def yolo_label_to_xyxy(norm, w, h):\n",
        "    \"\"\"Convert YOLO [xc,yc,bw,bh] normalized coords to pixel coords.\"\"\"\n",
        "    xc, yc, bw, bh = norm\n",
        "    xc, yc, bw, bh = xc*w, yc*h, bw*w, bh*h\n",
        "    return [xc - bw/2, yc - bh/2, xc + bw/2, yc + bh/2]\n",
        "\n",
        "def parse_label_file(label_path):\n",
        "    \"\"\"Read YOLO label .txt file and return (class, bbox) pairs.\"\"\"\n",
        "    labels = []\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 5:\n",
        "                    cls = int(parts[0]); norm = list(map(float, parts[1:5]))\n",
        "                    labels.append((cls, norm))\n",
        "    return labels\n",
        "\n",
        "def save_weights_copy(src_path, dest_dir, run_name):\n",
        "    \"\"\"Copy trained weights into a central folder for easy access.\"\"\"\n",
        "    os.makedirs(dest_dir, exist_ok=True)\n",
        "    if src_path and os.path.exists(src_path):\n",
        "        dest = os.path.join(dest_dir, f\"{run_name}_{Path(src_path).name}\")\n",
        "        shutil.copy(src_path, dest)\n",
        "        return dest\n",
        "    return None\n",
        "\n",
        "# ---------------- W&B Resume Utilities ----------------\n",
        "def wandb_run_id_from_name(name):\n",
        "    \"\"\"Generate stable hash-based W&B run ID for resuming.\"\"\"\n",
        "    return hashlib.sha1(name.encode()).hexdigest()[:12]\n",
        "\n",
        "def stable_run_name(task, cfg):\n",
        "    \"\"\"Create a consistent run name based on hyperparameters.\"\"\"\n",
        "    return f\"{task}_e{cfg['epochs']}_b{cfg['batch']}_lr{cfg['lr0']}_opt{cfg['optimizer']}_p{cfg['patience']}\"\n",
        "\n",
        "def latest_checkpoint(run_dir):\n",
        "    \"\"\"Find the most recent checkpoint in the given run directory.\"\"\"\n",
        "    weights = os.path.join(run_dir, \"weights\")\n",
        "    last = os.path.join(weights, \"last.pt\")\n",
        "    best = os.path.join(weights, \"best.pt\")\n",
        "    if os.path.exists(last): return last\n",
        "    if os.path.exists(best): return best\n",
        "    ckpts = sorted(glob.glob(os.path.join(weights, \"epoch*.pt\")))\n",
        "    return ckpts[-1] if ckpts else None\n",
        "\n",
        "# ---------------- Main Training + Logging ----------------\n",
        "def run_one_task(task, base_model, cfg, results_base):\n",
        "    \"\"\"Train, evaluate, and log metrics for a single YOLO task.\"\"\"\n",
        "    model = YOLO(base_model)\n",
        "    base_run_name = stable_run_name(task, cfg)\n",
        "    project_dir = os.path.join(results_base, task, base_run_name)\n",
        "    os.makedirs(project_dir, exist_ok=True)\n",
        "\n",
        "    # üîÅ Resume logic\n",
        "    ckpt = latest_checkpoint(project_dir)\n",
        "    do_resume = ckpt is not None\n",
        "\n",
        "    # üìä Initialize W&B with descriptive name\n",
        "    wandb, _ = ensure_wandb()\n",
        "    if WANDB_ENABLE and wandb is not None:\n",
        "        run_id = wandb_run_id_from_name(base_run_name)\n",
        "        wandb_name = (\n",
        "            f\"{task.upper()} | e={cfg['epochs']} | b={cfg['batch']} | \"\n",
        "            f\"lr={cfg['lr0']} | opt={cfg['optimizer']} | p={cfg['patience']} | {datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "        )\n",
        "        wandb.init(\n",
        "            project=WANDB_PROJECT,\n",
        "            name=wandb_name,\n",
        "            group=task,\n",
        "            id=run_id,\n",
        "            resume=\"allow\"\n",
        "        )\n",
        "        wandb.config.update(cfg)\n",
        "        wandb.config.update({\"task\": task, \"model\": base_model, \"dataset\": ROBOFLOW_DATA_YAML})\n",
        "\n",
        "    print(f\"\\n--- Training {task.upper()} | Run: {base_run_name} ---\")\n",
        "    if do_resume:\n",
        "        print(f\"üîÅ Resuming from checkpoint: {ckpt}\")\n",
        "    else:\n",
        "        print(\"üÜï Starting fresh training...\")\n",
        "\n",
        "    # Start training with checkpoint saving and resume enabled\n",
        "    # TRAIIIIIIIIIINNNNNNNNNN\n",
        "    t0 = time.time()\n",
        "    model.train(\n",
        "        data=ROBOFLOW_DATA_YAML,\n",
        "        epochs=cfg[\"epochs\"],\n",
        "        batch=cfg[\"batch\"],\n",
        "        imgsz=IMG_SIZE,\n",
        "        optimizer=cfg[\"optimizer\"],\n",
        "        lr0=cfg[\"lr0\"],\n",
        "        patience=cfg[\"patience\"],\n",
        "        project=os.path.join(results_base, task),\n",
        "        name=base_run_name,\n",
        "        resume=do_resume,\n",
        "        save_period=cfg[\"save_period\"]\n",
        "    )\n",
        "    elapsed = round(time.time() - t0, 2)\n",
        "    print(f\"‚è±Ô∏è Training finished in {elapsed} seconds\")\n",
        "\n",
        "    # ---------------- Validation + Metrics ----------------\n",
        "    # VAAAAAAAALLLIIIIDDAAAAAAATION\n",
        "    val_results = model.val()\n",
        "    metrics = {}\n",
        "    try:\n",
        "        metrics[\"mAP@0.5\"] = float(val_results.box.map50)\n",
        "        metrics[\"mAP@0.5:0.95\"] = float(val_results.box.map)\n",
        "        metrics[\"precision\"] = float(val_results.box.precision)\n",
        "        metrics[\"recall\"] = float(val_results.box.recall)\n",
        "        metrics[\"f1\"] = float(val_results.box.f1)\n",
        "    except Exception:\n",
        "        metrics = {k: None for k in [\"mAP@0.5\",\"mAP@0.5:0.95\",\"precision\",\"recall\",\"f1\"]}\n",
        "\n",
        "    # üß† Log key metrics to W&B\n",
        "    if WANDB_ENABLE and wandb is not None:\n",
        "        wandb.log(metrics)\n",
        "\n",
        "    # ---------------- Save weights ----------------\n",
        "    weights_dir = os.path.join(project_dir, \"weights\")\n",
        "    best_w = os.path.join(weights_dir, \"best.pt\")\n",
        "    last_w = os.path.join(weights_dir, \"last.pt\")\n",
        "    chosen = best_w if os.path.exists(best_w) else (last_w if os.path.exists(last_w) else None)\n",
        "    saved_copy = save_weights_copy(chosen, os.path.join(results_base, \"saved_models\"), base_run_name)\n",
        "\n",
        "    # ---------------- Inference + Visualization ----------------\n",
        "    infer_folder = os.path.join(project_dir, \"inference_results\")\n",
        "    os.makedirs(infer_folder, exist_ok=True)\n",
        "    val_images_path = os.path.join(dataset.location, \"valid\", \"images\")\n",
        "    val_imgs = glob.glob(f\"{val_images_path}/*.jpg\")\n",
        "    sample_imgs = random.sample(val_imgs, min(3, len(val_imgs)))\n",
        "\n",
        "    if sample_imgs:\n",
        "        print(f\"üñºÔ∏è Performing inference on {len(sample_imgs)} sample images...\")\n",
        "        model.predict(source=sample_imgs, save=True, project=infer_folder, name=\"sample_preds\")\n",
        "        for img in glob.glob(f\"{infer_folder}/sample_preds/*.jpg\")[:3]:\n",
        "            display(IPyImage(filename=img, width=400))\n",
        "\n",
        "    # ---------------- Confusion Matrix + Per-Class Metrics ----------------\n",
        "    data_meta = load_data_yaml(ROBOFLOW_DATA_YAML)\n",
        "    class_names = data_meta.get(\"names\", [])\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    for img_path in val_imgs:\n",
        "        res = model.predict(img_path, imgsz=IMG_SIZE, conf=0.25, iou=0.45, stream=False, verbose=False)[0]\n",
        "        preds = [int(b[5]) for b in res.boxes.data.tolist()] if hasattr(res, \"boxes\") else []\n",
        "        label_path = Path(img_path).with_suffix(\".txt\")\n",
        "        gt = parse_label_file(str(label_path))\n",
        "        y_true.extend([g[0] for g in gt])\n",
        "        y_pred.extend(preds[:len(gt)])  # align predictions\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6,6))\n",
        "    ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names).plot(ax=ax)\n",
        "    plt.title(f\"Confusion Matrix ({task}) | Acc={acc:.3f}\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(project_dir, \"confusion_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # üßæ Log final results to W&B\n",
        "    if WANDB_ENABLE and wandb is not None:\n",
        "        wandb.log({\"confusion_matrix\": wandb.Image(os.path.join(project_dir, \"confusion_matrix.png\"))})\n",
        "        wandb.finish()\n",
        "\n",
        "    # ---------------- Return Record ----------------\n",
        "    return {\n",
        "        \"task\": task,\n",
        "        \"run_name\": base_run_name,\n",
        "        \"elapsed_seconds\": elapsed,\n",
        "        **metrics,\n",
        "        \"accuracy\": acc,\n",
        "        \"saved_model\": saved_copy\n",
        "    }\n",
        "\n",
        "# ---------------- Zipping All Results ----------------\n",
        "def zip_all_results(results_base, timestamp):\n",
        "    \"\"\"Zip all results: weights, plots, metrics, inferences, CSVs.\"\"\"\n",
        "    zip_name = os.path.join(results_base, f\"all_results_{timestamp}.zip\")\n",
        "    with zipfile.ZipFile(zip_name, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, _, files in os.walk(results_base):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, start=results_base)\n",
        "                zipf.write(file_path, arcname)\n",
        "    print(f\"\\nüì¶ All results zipped: {zip_name}\")\n",
        "    return zip_name\n",
        "\n",
        "# ---------------- Entry Point ----------------\n",
        "if __name__ == \"__main__\":\n",
        "    ensure_tensorboard()\n",
        "    data_meta = load_data_yaml(ROBOFLOW_DATA_YAML)\n",
        "    print(\"üìä Classes:\", data_meta.get(\"names\"))\n",
        "    summary_rows = []\n",
        "\n",
        "    for task in TASKS:\n",
        "        base_model = MODEL_MAP[task]\n",
        "        rec = run_one_task(task, base_model, MANUAL_CONFIG, RESULTS_BASE)\n",
        "        print(\"Run Summary:\", rec)\n",
        "        summary_rows.append(rec)\n",
        "\n",
        "    pd.DataFrame(summary_rows).to_csv(SUMMARY_CSV, index=False)\n",
        "    print(f\"\\n‚úÖ Manual tuning complete. Summary saved to: {SUMMARY_CSV}\")\n",
        "\n",
        "    acc_vals = [r[\"accuracy\"] for r in summary_rows if r.get(\"accuracy\")]\n",
        "    if acc_vals:\n",
        "        print(f\"üìà Average Classification Accuracy: {np.mean(acc_vals):.3f}\")\n",
        "\n",
        "    zip_all_results(RESULTS_BASE, TIMESTAMP)\n",
        "\n"
      ],
      "metadata": {
        "id": "1TGBzEMtk8yU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "outputId": "ec90136f-41ca-4f38-99cf-cb257b7303a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "Current W&B status: 02a2986eed98555093c4c2920a04c631a89430cc\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "‚úÖ Dataset downloaded successfully!\n",
            "üìÇ YAML: /content/MOR-V4-1/data.yaml\n",
            "üìä Classes: ['Over-Cooked', 'Perfectly-Cooked', 'Under-Cooked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmmtampogao\u001b[0m (\u001b[33mmmtampogao-university-of-the-philippines\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251104_024523-9580041e3389</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/mmtampogao-university-of-the-philippines/Copra-YOLOv11-Tuning/runs/9580041e3389' target=\"_blank\">CLS | e=100 | b=16 | lr=0.001 | opt=auto | p=100 | 20251104_024521</a></strong> to <a href='https://wandb.ai/mmtampogao-university-of-the-philippines/Copra-YOLOv11-Tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mmtampogao-university-of-the-philippines/Copra-YOLOv11-Tuning' target=\"_blank\">https://wandb.ai/mmtampogao-university-of-the-philippines/Copra-YOLOv11-Tuning</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mmtampogao-university-of-the-philippines/Copra-YOLOv11-Tuning/runs/9580041e3389' target=\"_blank\">https://wandb.ai/mmtampogao-university-of-the-philippines/Copra-YOLOv11-Tuning/runs/9580041e3389</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training CLS | Run: cls_e100_b16_lr0.001_optauto_p100 ---\n",
            "üÜï Starting fresh training...\n",
            "Ultralytics 8.3.224 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/MOR-V4-1/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=cls_e100_b16_lr0.001_optauto_p1004, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/yolo_copra/copra_yolo11_manual_results/cls, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/yolo_copra/copra_yolo11_manual_results/cls/cls_e100_b16_lr0.001_optauto_p1004, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Dataset '/content/MOR-V4-1/data.yaml' error ‚ùå Classification datasets must be a directory (data=\"path/to/dir\") not a file (data=\"/content/MOR-V4-1/data.yaml\"), See https://docs.ultralytics.com/datasets/classify/",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"classify\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cls_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ndjson\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/utils.py\u001b[0m in \u001b[0;36mcheck_cls_dataset\u001b[0;34m(dataset, split)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    511\u001b[0m                 \u001b[0;34mf'Classification datasets must be a directory (data=\"path/to/dir\") not a file (data=\"{dataset}\"), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification datasets must be a directory (data=\"path/to/dir\") not a file (data=\"/content/MOR-V4-1/data.yaml\"), See https://docs.ultralytics.com/datasets/classify/",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4187084469.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTASKS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODEL_MAP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_one_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMANUAL_CONFIG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRESULTS_BASE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Run Summary:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0msummary_rows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4187084469.py\u001b[0m in \u001b[0;36mrun_one_task\u001b[0;34m(task, base_model, cfg, results_base)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;31m# TRAIIIIIIIIIINNNNNNNNNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     model.train(\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mROBOFLOW_DATA_YAML\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# manually set model only if not resuming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/classify/train.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"imgsz\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0moverrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"imgsz\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_model_file_from_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch_distributed_zero_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL_RANK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# avoid auto-downloading dataset multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    646\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"yaml_file\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# for validating 'yolo train data=url.zip' usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memojis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset '{clean_url(self.args.data)}' error ‚ùå {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Overriding class names with single class.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Dataset '/content/MOR-V4-1/data.yaml' error ‚ùå Classification datasets must be a directory (data=\"path/to/dir\") not a file (data=\"/content/MOR-V4-1/data.yaml\"), See https://docs.ultralytics.com/datasets/classify/"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ONpP5Smhuikj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}