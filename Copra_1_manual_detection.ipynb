{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmTampz/Copra_YOLOv11_v12_Colab_Notebooks/blob/main/Copra_1_manual_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fgHH8hftgVWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "530577d4-4bd8-4e2c-8be5-4b078d8c333d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.228-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.228-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.228 ultralytics-thop-2.0.18\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.10)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.11-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.10.5)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Collecting pi-heif<2 (from roboflow)\n",
            "  Downloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.60.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.4)\n",
            "Downloading roboflow-1.2.11-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.1 pillow-avif-plugin-1.5.2 roboflow-1.2.11\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# ğŸ“¦ ENVIRONMENT SETUP for YOLOv11 Thesis (Colab)\n",
        "\n",
        "# Core deep learning and YOLO library\n",
        "!pip install -U ultralytics\n",
        "\n",
        "# Core data handling, visualization, and ML utilities\n",
        "!pip install pandas matplotlib seaborn pillow scikit-learn\n",
        "\n",
        "#local dashboard:  monitoring and logging\n",
        "!pip install tensorboard tqdm\n",
        "\n",
        "# Roboflow integration\n",
        "!pip install roboflow\n",
        "\n",
        "# cloud-connected research tracker\n",
        "!pip -q install wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEYK9F_5ktKg",
        "outputId": "5b47306a-fb51-49c5-a201-644707320b9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.228 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 38.4/235.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "import torch, ultralytics, pandas as pd, matplotlib, seaborn, PIL, sklearn, tqdm, tensorboard\n",
        "\n",
        "print(f\"PyTorch version : {torch.__version__}\")\n",
        "print(f\"CUDA available  : {torch.cuda.is_available()}\")\n",
        "print(f\"Ultralytics ver : {ultralytics.__version__}\")\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDPGsi9_-vfW",
        "outputId": "2d318608-adee-4d7c-bf65-fe4cc110146a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Drive not mounted. Using local storage.\n",
            "ğŸ“ Results directory: /content/yolo_copra/copra_yolo11_detect_results_new\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in MOR-V6-1 to yolov11:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65923/65923 [00:04<00:00, 13348.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to MOR-V6-1 in yolov11:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8506/8506 [00:00<00:00, 10157.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Dataset loaded with 3 classes: ['Over-Cooked', 'Perfectly-Cooked', 'Under-Cooked']\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================\n",
        "# ğŸ§© BLOCK 1 â€” SETUP, IMPORTS, AND CONFIGURATION\n",
        "# ===============================================================\n",
        "\n",
        "import os, time, json, yaml, glob, zipfile, random\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, ConfusionMatrixDisplay,\n",
        "    precision_recall_fscore_support, accuracy_score,\n",
        ")\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from roboflow import Roboflow\n",
        "import wandb\n",
        "from IPython.display import display\n",
        "\n",
        "# ---------------- MOUNT GOOGLE DRIVE ----------------\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    DRIVE_OK = True\n",
        "    print(\"âœ… Google Drive mounted successfully.\")\n",
        "except Exception:\n",
        "    DRIVE_OK = False\n",
        "    print(\"âš ï¸ Drive not mounted. Using local storage.\")\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/yolo_copra\" if DRIVE_OK else \"/content/yolo_copra\"\n",
        "\n",
        "# âœ… Updated folder path for saving results\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, \"copra_yolo11_detect_results_new\")\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "print(f\"ğŸ“ Results directory: {RESULTS_DIR}\")\n",
        "\n",
        "# ---------------- WANDB SETUP ----------------\n",
        "os.environ[\"WANDB_API_KEY\"] = \"02a2986eed98555093c4c2920a04c631a89430cc\"\n",
        "!wandb login $WANDB_API_KEY --relogin\n",
        "WANDB_PROJECT = \"Copra-YOLOv11-Detection\"\n",
        "\n",
        "# ---------------- LOAD ROBOFLOW DATASET ----------------\n",
        "rf = Roboflow(api_key=\"LS1Ohi2OQZ178OOqQ4zc\")\n",
        "project = rf.workspace(\"cv-opfhv\").project(\"mor-v6-jj3ic\")\n",
        "dataset = project.version(1).download(\"yolov11\")\n",
        "DATA_YAML = os.path.join(dataset.location, \"data.yaml\")\n",
        "\n",
        "with open(DATA_YAML, \"r\") as f:\n",
        "    meta = yaml.safe_load(f)\n",
        "class_names = [c for c in meta[\"names\"] if c.lower() not in [\"background\", \"null\"]]\n",
        "print(f\"âœ… Dataset loaded with {len(class_names)} classes: {class_names}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "72Kns1ZX-1MX"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# 4ï¸âƒ£ CONFIGURATION\n",
        "# ===============================================================\n",
        "CONFIG = dict(\n",
        "    epochs=300,\n",
        "    batch=16,\n",
        "    lr0=0.001,\n",
        "    patience=100,\n",
        "    optimizer=\"auto\",\n",
        "    imgsz=640,\n",
        ")\n",
        "MODEL_PATH = \"yolo11n.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1TGBzEMtk8yU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---------------- UTILITIES ----------------\n",
        "def latest_checkpoint(base_dir: str):\n",
        "    ckpts = glob.glob(os.path.join(base_dir, \"**\", \"*.pt\"), recursive=True)\n",
        "    return max(ckpts, key=os.path.getmtime) if ckpts else None\n",
        "\n",
        "def zip_results(folder: str):\n",
        "    zip_path = os.path.join(folder, f\"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip\")\n",
        "    with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
        "        for root, _, files in os.walk(folder):\n",
        "            for file in files:\n",
        "                fp = os.path.join(root, file)\n",
        "                z.write(fp, os.path.relpath(fp, start=folder))\n",
        "    return zip_path\n",
        "\n",
        "def parse_label_file(label_path: str):\n",
        "    labels = []\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path) as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 5:\n",
        "                    cls = int(parts[0])\n",
        "                    if cls < len(class_names):\n",
        "                        labels.append(cls)\n",
        "    return labels\n",
        "\n",
        "def save_and_show(fig_path: str, title: str = None):\n",
        "    if title: plt.title(title)\n",
        "    plt.tight_layout(); plt.savefig(fig_path, bbox_inches=\"tight\"); plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M6fQx1-d_Xrt"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# ğŸ§© BLOCK 2 â€” TRAINING + VALIDATION (FIXED: SINGLE FOLDER OUTPUT)\n",
        "# ===============================================================\n",
        "def train_yolo_detection():\n",
        "    model = YOLO(MODEL_PATH)\n",
        "    print(\"ğŸš€ Starting YOLOv11 Detection Training...\")\n",
        "\n",
        "    # Auto-resume detection\n",
        "    existing_runs = sorted([d for d in os.listdir(RESULTS_DIR) if os.path.isdir(os.path.join(RESULTS_DIR, d))])\n",
        "    resume, run_name, ckpt = False, None, None\n",
        "    if existing_runs:\n",
        "        latest_run_dir = os.path.join(RESULTS_DIR, existing_runs[-1])\n",
        "        ckpt = latest_checkpoint(latest_run_dir)\n",
        "        if ckpt:\n",
        "            resume, run_name = True, os.path.basename(latest_run_dir)\n",
        "            print(f\"ğŸ” Auto-resume detected: {ckpt}\")\n",
        "        else:\n",
        "            print(\"âš ï¸ No valid checkpoint found. Starting new training.\")\n",
        "    else:\n",
        "        print(\"ğŸ†• Starting fresh training run.\")\n",
        "\n",
        "    # W&B naming and setup\n",
        "    if not run_name:\n",
        "        run_name = f\"det_e{CONFIG['epochs']}_b{CONFIG['batch']}_lr{CONFIG['lr0']}_{CONFIG['optimizer']}_img{CONFIG['imgsz']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "    run_dir = os.path.join(RESULTS_DIR, run_name)\n",
        "    os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "    wandb.init(project=WANDB_PROJECT, name=run_name, resume=\"allow\", config=CONFIG)\n",
        "    wandb.config.update({\"group\": CONFIG[\"optimizer\"]})\n",
        "\n",
        "    # ===============================================================\n",
        "    # ğŸ‹ï¸â€â™‚ï¸ TRAINING STARTS\n",
        "    # ===============================================================\n",
        "    start_time = time.time()\n",
        "    results = model.train(\n",
        "        data=DATA_YAML,\n",
        "        task=\"detect\",\n",
        "        epochs=CONFIG[\"epochs\"],\n",
        "        batch=CONFIG[\"batch\"],\n",
        "        lr0=CONFIG[\"lr0\"],\n",
        "        patience=CONFIG[\"patience\"],\n",
        "        optimizer=CONFIG[\"optimizer\"],\n",
        "        imgsz=CONFIG[\"imgsz\"],\n",
        "\n",
        "        # ğŸŸ© CHANGE 1: Force YOLO to save inside the same run_dir\n",
        "        project=run_dir,   # instead of RESULTS_DIR\n",
        "        name=\"\",           # prevents YOLO from creating nested folders\n",
        "        exist_ok=True,     # overwrite instead of creating â€œ_2â€\n",
        "        save_period=5,\n",
        "        resume=False,\n",
        "    )\n",
        "\n",
        "    # ğŸŸ¥ REMOVE this line â€” YOLO already saves in run_dir\n",
        "    # run_dir = str(results.save_dir)\n",
        "\n",
        "    print(f\"ğŸ Training complete! All outputs stored in: {run_dir}\")\n",
        "\n",
        "    # ===============================================================\n",
        "    # ğŸ” VALIDATION\n",
        "    # ===============================================================\n",
        "    print(\"ğŸ” Running validation...\")\n",
        "    val = model.val(\n",
        "        project=os.path.join(run_dir, \"validation\"),  # ğŸŸ© CHANGE 2: create subfolder\n",
        "        name=\"\", exist_ok=True\n",
        "    )\n",
        "\n",
        "    # ğŸ“Š Metric extraction (Ultralytics v8/11+)\n",
        "    metrics = {\n",
        "        \"Precision\": float(val.box.mp),\n",
        "        \"Recall\": float(val.box.mr),\n",
        "        \"mAP@0.5\": float(val.box.map50),\n",
        "        \"mAP@0.5:0.95\": float(val.box.map),\n",
        "    }\n",
        "    metrics[\"F1\"] = 2 * (metrics[\"Precision\"] * metrics[\"Recall\"]) / (\n",
        "        metrics[\"Precision\"] + metrics[\"Recall\"] + 1e-6\n",
        "    )\n",
        "\n",
        "    # Display + Save\n",
        "    dfm = pd.DataFrame([metrics])\n",
        "    display(dfm.style.background_gradient(cmap=\"YlGnBu\").format(precision=3))\n",
        "    dfm.to_csv(os.path.join(run_dir, \"summary_metrics.csv\"), index=False)\n",
        "    wandb.log(metrics)\n",
        "    wandb.finish()\n",
        "\n",
        "    # ===============================================================\n",
        "    # â±ï¸ TIMING + CHECKPOINT VALIDATION\n",
        "    # ===============================================================\n",
        "    elapsed = time.time() - start_time\n",
        "    hours, minutes = divmod(elapsed / 60, 60)\n",
        "    print(f\"ğŸ•’ Training + Validation completed in {int(hours)}h {int(minutes)}m ({elapsed:.2f}s total)\")\n",
        "    print(f\"ğŸ“ Run saved in: {run_dir}\")\n",
        "\n",
        "    # âœ… FIX 3 â€” Confirm weights actually exist\n",
        "    weights_path = os.path.join(run_dir, \"weights\")\n",
        "    if os.path.exists(weights_path):\n",
        "        print(\"âœ… Weights folder verified:\", weights_path)\n",
        "        os.system(f'ls \"{weights_path}\"')\n",
        "    else:\n",
        "        print(\"âš ï¸ Warning: No weights folder found. Drive may have unmounted or run interrupted.\")\n",
        "\n",
        "    return run_dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bkxcyOBp8KkY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G-OWWD1qc423"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# ğŸ§© BLOCK 3 â€” TESTING (INFERENCE)\n",
        "# ===============================================================\n",
        "def run_yolo_detection_test(run_dir: str):\n",
        "    test_dir = os.path.join(run_dir, \"test_results\")\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "    best_path = os.path.join(run_dir, \"weights\", \"best.pt\")\n",
        "\n",
        "    if not os.path.exists(best_path):\n",
        "        candidates = glob.glob(os.path.join(BASE_DIR, \"**\", \"best.pt\"), recursive=True)\n",
        "        if not candidates:\n",
        "            raise FileNotFoundError(\"âŒ No best.pt found!\")\n",
        "        best_path = max(candidates, key=os.path.getmtime)\n",
        "    print(f\"âœ… Using checkpoint: {best_path}\")\n",
        "\n",
        "    model = YOLO(best_path)\n",
        "    test_imgs = glob.glob(os.path.join(dataset.location, \"test\", \"images\", \"*.jpg\"))\n",
        "    print(f\"ğŸ§© Found {len(test_imgs)} test images.\")\n",
        "\n",
        "    y_true, y_pred, conf_scores = [], [], []\n",
        "    for img_path in test_imgs:\n",
        "        res = model.predict(img_path, conf=0.25, iou=0.45, verbose=False)[0]\n",
        "        gt = parse_label_file(Path(img_path).with_suffix(\".txt\"))\n",
        "        img = cv2.imread(img_path)\n",
        "        for i, box in enumerate(res.boxes.xyxy):\n",
        "            cls = int(res.boxes.cls[i]); conf = float(res.boxes.conf[i])\n",
        "            conf_scores.append(conf); y_pred.append(cls)\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "            cv2.putText(img, f\"{class_names[cls]} {conf:.2f}\", (x1, max(20, y1-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
        "        cv2.imwrite(os.path.join(test_dir, f\"bbox_{Path(img_path).name}\"), img[:, :, ::-1])\n",
        "        y_true.extend(gt)\n",
        "\n",
        "    print(f\"âœ… Inference complete. Results saved in {test_dir}\")\n",
        "    return y_true, y_pred, conf_scores, test_dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0Ggd-k1wDG9t"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# ğŸ§© BLOCK 4 â€” VISUALIZATION (POST-TEST METRIC ANALYSIS)\n",
        "# ===============================================================\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n",
        "\n",
        "# ğŸ”¹ Class names\n",
        "class_names = [\"Undercooked\", \"Perfectly Cooked\", \"Overcooked\"]\n",
        "\n",
        "def visualize_test_results(y_true, y_pred, conf_scores, test_dir):\n",
        "    valid_idx = list(range(len(class_names)))\n",
        "    y_true = [y for y in y_true if y in valid_idx]\n",
        "    y_pred = [y for y in y_pred if y in valid_idx]\n",
        "\n",
        "    # Compute metrics\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(\n",
        "        y_true, y_pred, labels=valid_idx, zero_division=0\n",
        "    )\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=valid_idx)\n",
        "    conf_scores = np.array(conf_scores)\n",
        "    mean_conf, std_conf = np.mean(conf_scores), np.std(conf_scores)\n",
        "    ci_low, ci_high = mean_conf - std_conf, mean_conf + std_conf\n",
        "    print(f\"ğŸ“ˆ Confidence Interval: {mean_conf:.3f} Â± {std_conf:.3f} â†’ [{ci_low:.3f}, {ci_high:.3f}]\")\n",
        "\n",
        "    # Export metrics\n",
        "    metrics_df = pd.DataFrame({\n",
        "        \"Label\": class_names,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-Score\": f1,\n",
        "        \"Accuracy (%)\": (cm.diagonal() / cm.sum(axis=1)) * 100\n",
        "    })\n",
        "    display(metrics_df.style.background_gradient(cmap=\"YlOrBr\").format(precision=3))\n",
        "    metrics_df.to_csv(os.path.join(test_dir, \"test_metrics.csv\"), index=False)\n",
        "\n",
        "    # ğŸ¯ Confusion Matrix\n",
        "    plt.figure(figsize=(6,6))\n",
        "    ConfusionMatrixDisplay(cm, display_labels=class_names).plot(values_format=\".0f\", cmap=\"Blues\")\n",
        "    plt.title(\"Confusion Matrix (YOLOv11)\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(test_dir, \"confusion_matrix_test.png\"))\n",
        "    plt.show()\n",
        "\n",
        "    # ğŸ“Š Metric Graphs\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.bar(class_names, metrics_df[\"Accuracy (%)\"], color=\"cornflowerblue\")\n",
        "    plt.title(\"Per-Class Accuracy (YOLOv11)\")\n",
        "    plt.ylim(0,100); plt.grid(alpha=0.4)\n",
        "    plt.tight_layout(); plt.savefig(os.path.join(test_dir,\"per_class_accuracy_test.png\")); plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.bar(class_names, precision, color=\"seagreen\")\n",
        "    plt.title(\"Per-Class Precision (YOLOv11)\")\n",
        "    plt.ylim(0,1); plt.grid(alpha=0.4)\n",
        "    plt.tight_layout(); plt.savefig(os.path.join(test_dir,\"per_class_precision_test.png\")); plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.bar(class_names, recall, color=\"gold\")\n",
        "    plt.title(\"Per-Class Recall (YOLOv11)\")\n",
        "    plt.ylim(0,1); plt.grid(alpha=0.4)\n",
        "    plt.tight_layout(); plt.savefig(os.path.join(test_dir,\"per_class_recall_test.png\")); plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.bar(class_names, f1, color=\"tomato\")\n",
        "    plt.title(\"Per-Class F1-Score (YOLOv11)\")\n",
        "    plt.ylim(0,1); plt.grid(alpha=0.4)\n",
        "    plt.tight_layout(); plt.savefig(os.path.join(test_dir,\"per_class_f1_test.png\")); plt.show()\n",
        "\n",
        "    # ğŸ“ˆ Confidence Histogram\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.hist(conf_scores,bins=20,color=\"skyblue\",edgecolor=\"k\")\n",
        "    plt.axvline(mean_conf,color=\"red\",ls=\"--\",label=f\"Î¼={mean_conf:.2f}\")\n",
        "    plt.legend(); plt.xlabel(\"Confidence\"); plt.ylabel(\"Frequency\")\n",
        "    plt.title(\"Confidence Distribution (YOLOv11)\")\n",
        "    plt.tight_layout(); plt.savefig(os.path.join(test_dir,\"confidence_hist_test.png\")); plt.show()\n",
        "\n",
        "    # ğŸ”µ Precisionâ€“Recall Scatter\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.scatter(precision, recall, s=80, c='dodgerblue')\n",
        "    for i,cls in enumerate(class_names):\n",
        "        plt.text(precision[i]+0.01, recall[i], cls, fontsize=9)\n",
        "    plt.xlabel(\"Precision\"); plt.ylabel(\"Recall\")\n",
        "    plt.title(\"Precisionâ€“Recall Scatter (YOLOv11)\")\n",
        "    plt.grid(True,ls=\"--\",alpha=0.5)\n",
        "    plt.tight_layout(); plt.savefig(os.path.join(test_dir,\"precision_recall_scatter_test.png\")); plt.show()\n",
        "\n",
        "    print(f\"âœ… Visualizations saved in: {test_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cp0T8ASuG07x"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# ğŸ§© BLOCK 5A â€” AUTO-RESUME OR TRAIN (FINAL FIXED VERSION)\n",
        "# ===============================================================\n",
        "import os, glob\n",
        "from ultralytics import YOLO\n",
        "\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/yolo_copra/copra_yolo11_detect_results_new\"\n",
        "\n",
        "def auto_resume_training():\n",
        "    \"\"\"\n",
        "    Resume YOLOv11 detection training if a checkpoint exists.\n",
        "    If none found, automatically start a new training run using train_yolo_detection().\n",
        "    \"\"\"\n",
        "    candidate_ckpts = [\n",
        "        ckpt for ckpt in glob.glob(os.path.join(RESULTS_DIR, \"**\", \"*.pt\"), recursive=True)\n",
        "        if any(x in ckpt for x in [\"last.pt\", \"best.pt\", \"epoch_\"])\n",
        "    ]\n",
        "\n",
        "    # âœ… Case 1: No checkpoints found â†’ train fresh model\n",
        "    if not candidate_ckpts:\n",
        "        print(\"âš ï¸ No checkpoints found â€” starting a fresh YOLOv11 training run...\")\n",
        "        run_dir = train_yolo_detection()  # your function already includes validation\n",
        "        print(\"âœ… Initial training (and validation) completed successfully.\")\n",
        "        return run_dir\n",
        "\n",
        "    # âœ… Case 2: Checkpoint found â†’ resume from last/best\n",
        "    ckpt_path = max(candidate_ckpts, key=os.path.getmtime)\n",
        "    run_dir = os.path.dirname(os.path.dirname(ckpt_path))\n",
        "    print(f\"âš™ï¸ Found checkpoint: {ckpt_path}\")\n",
        "\n",
        "    DATA_YAML = os.path.join(dataset.location, \"data.yaml\")\n",
        "    if not os.path.exists(DATA_YAML):\n",
        "        raise FileNotFoundError(f\"âŒ Dataset YAML not found at {DATA_YAML}\")\n",
        "\n",
        "    try:\n",
        "        print(f\"ğŸ“‚ Attempting to resume training from: {run_dir}\")\n",
        "        model = YOLO(ckpt_path)\n",
        "        model.train(\n",
        "            resume=True,\n",
        "            data=DATA_YAML,\n",
        "            project=RESULTS_DIR,\n",
        "            name=os.path.basename(run_dir),\n",
        "        )\n",
        "        print(\"ğŸ¯ Training resumed successfully.\")\n",
        "        return run_dir\n",
        "\n",
        "    except AssertionError as e:\n",
        "        if \"nothing to resume\" in str(e):\n",
        "            print(\"âœ… Training already completed. Proceeding directly to testing phase.\")\n",
        "            return run_dir\n",
        "        else:\n",
        "            raise e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "qJkiC_SDfH3Q",
        "outputId": "35b2e71f-196b-4ca3-912a-7d87ac5f2176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ No checkpoints found â€” starting a fresh YOLOv11 training run...\n",
            "ğŸš€ Starting YOLOv11 Detection Training...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/yolo_copra/copra_yolo11_detect_results_new'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3577485861.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# ğŸ” STEP 0 â€” RESUME OR LOCATE MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# ===============================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mrun_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauto_resume_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-460951899.py\u001b[0m in \u001b[0;36mauto_resume_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcandidate_ckpts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âš ï¸ No checkpoints found â€” starting a fresh YOLOv11 training run...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mrun_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_yolo_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# your function already includes validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âœ… Initial training (and validation) completed successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-466037468.py\u001b[0m in \u001b[0;36mtrain_yolo_detection\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Auto-resume detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mexisting_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESULTS_DIR\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESULTS_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mresume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexisting_runs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/yolo_copra/copra_yolo11_detect_results_new'"
          ]
        }
      ],
      "source": [
        "# ===============================================================\n",
        "# ğŸ§  BLOCK 5B â€” TEST MODEL AFTER TRAINING (SYNCHRONIZED FLOW, FINAL)\n",
        "# ===============================================================\n",
        "import os, glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/yolo_copra/copra_yolo11_detect_results_new\"\n",
        "\n",
        "# ===============================================================\n",
        "# ğŸ” STEP 0 â€” RESUME OR LOCATE MODEL\n",
        "# ===============================================================\n",
        "run_dir = auto_resume_training()\n",
        "\n",
        "if run_dir is None:\n",
        "    print(\"ğŸš€ No resume or prior training detected â€” locating latest trained model...\")\n",
        "    best_models = glob.glob(os.path.join(RESULTS_DIR, \"**\", \"best.pt\"), recursive=True)\n",
        "    if not best_models:\n",
        "        raise FileNotFoundError(\"âŒ No best.pt found for testing phase.\")\n",
        "    latest_best = max(best_models, key=os.path.getmtime)\n",
        "    run_dir = os.path.dirname(os.path.dirname(latest_best))\n",
        "    model_path = latest_best\n",
        "else:\n",
        "    model_path = os.path.join(run_dir, \"weights\", \"best.pt\")\n",
        "    if not os.path.exists(model_path):\n",
        "        model_path = os.path.join(run_dir, \"weights\", \"last.pt\")\n",
        "\n",
        "# ===============================================================\n",
        "# ğŸ§© STEP 0.5 â€” AUTO-SYNC ACTUAL YOLO FOLDER (handles \"_2\" issue)\n",
        "# ===============================================================\n",
        "expected_weights = os.path.join(run_dir, \"weights\")\n",
        "if not os.path.exists(expected_weights):\n",
        "    print(f\"âš ï¸ Folder mismatch: {expected_weights} not found. Searching for true run folder...\")\n",
        "    run_name = os.path.basename(run_dir)\n",
        "    alt_candidates = glob.glob(os.path.join(RESULTS_DIR, run_name + \"*\"))\n",
        "    if alt_candidates:\n",
        "        run_dir = max(alt_candidates, key=os.path.getmtime)\n",
        "        print(f\"âš™ï¸ Synced run_dir to actual YOLO folder: {run_dir}\")\n",
        "        model_path = os.path.join(run_dir, \"weights\", \"best.pt\")\n",
        "        if not os.path.exists(model_path):\n",
        "            model_path = os.path.join(run_dir, \"weights\", \"last.pt\")\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"âŒ Could not find matching folder for {run_name}\")\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    raise FileNotFoundError(f\"âŒ Still no valid checkpoint found at {model_path}\")\n",
        "\n",
        "print(f\"âœ… Using model for testing: {model_path}\")\n",
        "\n",
        "# ===============================================================\n",
        "# ğŸ§ª STEP 1 â€” VALIDATION ON TEST SPLIT\n",
        "# ===============================================================\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Ensure test_results folder exists before saving\n",
        "test_dir = os.path.join(run_dir, \"test_results\")\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "print(f\"ğŸ“ Validation results will be saved under: {test_dir}\")\n",
        "\n",
        "metrics = model.val(\n",
        "    save_json=True,\n",
        "    save_hybrid=True,\n",
        "    imgsz=640,\n",
        "    project=test_dir,      # âœ… force save outputs in same folder\n",
        "    name=\"\",               # âœ… prevent nested folders\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "print(\"\\nğŸ“Š Validation Summary Metrics:\")\n",
        "for k, v in metrics.results_dict.items():\n",
        "    if isinstance(v, (int, float, np.floating)):\n",
        "        print(f\" - {k}: {v:.4f}\")\n",
        "    else:\n",
        "        print(f\" - {k}: {v}\")\n",
        "\n",
        "# âœ… Safe save to summary CSV\n",
        "metrics_df = pd.DataFrame([metrics.results_dict])\n",
        "summary_path = os.path.join(test_dir, \"summary_metrics.csv\")\n",
        "metrics_df.to_csv(summary_path, index=False)\n",
        "print(f\"ğŸ’¾ Summary metrics saved to: {summary_path}\")\n",
        "\n",
        "# ===============================================================\n",
        "# ğŸ§  STEP 2 â€” INFERENCE FOR DETAILED OUTPUTS (per-image predictions)\n",
        "# ===============================================================\n",
        "print(\"\\nğŸ” Running inference for per-image results...\")\n",
        "\n",
        "test_images = os.path.join(dataset.location, \"test\", \"images\")\n",
        "if not os.path.exists(test_images):\n",
        "    raise FileNotFoundError(f\"âŒ Test image folder not found: {test_images}\")\n",
        "else:\n",
        "    print(f\"ğŸ§© Found {len(glob.glob(os.path.join(test_images, '*.jpg')))} test images.\")\n",
        "\n",
        "pred_results = model.predict(\n",
        "    source=test_images,\n",
        "    save=True,\n",
        "    project=test_dir,    # âœ… all results under test_results/\n",
        "    name=\"predictions\",\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "y_true, y_pred, conf_scores = [], [], []\n",
        "for r in pred_results:\n",
        "    if r.boxes is not None:\n",
        "        preds = r.boxes\n",
        "        y_pred.extend(preds.cls.cpu().numpy())\n",
        "        conf_scores.extend(preds.conf.cpu().numpy())\n",
        "\n",
        "print(f\"âœ… Inference complete. Saved predictions to: {os.path.join(test_dir, 'predictions')}\")\n",
        "print(f\"ğŸ“‚ Test results fully stored in: {run_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQNPzLP3fHqK"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# ğŸ§© BLOCK 5C â€” VISUALIZE TEST RESULTS (TRUE CURVES + SAFETY PRINTS)\n",
        "# ===============================================================\n",
        "import os, glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, ConfusionMatrixDisplay,\n",
        "    precision_recall_fscore_support, precision_recall_curve\n",
        ")\n",
        "\n",
        "# ğŸ”¹ Class names for label IDs 0, 1, 2\n",
        "class_names = [\"Undercooked\", \"Perfectly Cooked\", \"Overcooked\"]\n",
        "\n",
        "def load_ground_truth_labels(labels_dir):\n",
        "    \"\"\"Read YOLO-format .txt files and extract class IDs.\"\"\"\n",
        "    y_true = []\n",
        "    if not os.path.exists(labels_dir):\n",
        "        print(f\"âš ï¸ Ground-truth labels directory not found: {labels_dir}\")\n",
        "        return y_true\n",
        "    label_files = glob.glob(os.path.join(labels_dir, \"*.txt\"))\n",
        "    if not label_files:\n",
        "        print(f\"âš ï¸ No label files found inside {labels_dir}\")\n",
        "        return y_true\n",
        "    for lf in label_files:\n",
        "        with open(lf) as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if parts:\n",
        "                    try:\n",
        "                        y_true.append(int(float(parts[0])))\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "    print(f\"âœ… Loaded {len(y_true)} ground-truth labels from {labels_dir}\")\n",
        "    return y_true\n",
        "\n",
        "\n",
        "def visualize_test_results(y_true, y_pred, conf_scores, test_dir):\n",
        "    \"\"\"Full metric and visual report (YOLOv11).\"\"\"\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "    print(f\"ğŸ“‚ Saving visual outputs to: {test_dir}\")\n",
        "\n",
        "    if len(y_true) == 0 or len(y_pred) == 0:\n",
        "        print(\"âš ï¸ Empty y_true or y_pred â€” skipping visualization.\")\n",
        "        return\n",
        "\n",
        "    valid_idx = list(range(len(class_names)))\n",
        "    y_true = [y for y in y_true if y in valid_idx]\n",
        "    y_pred = [y for y in y_pred if y in valid_idx]\n",
        "\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(\n",
        "        y_true, y_pred, labels=valid_idx, zero_division=0\n",
        "    )\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=valid_idx)\n",
        "    conf_scores = np.array(conf_scores) if conf_scores is not None else np.array([])\n",
        "\n",
        "    # ğŸ“Š Build DataFrame\n",
        "    metrics_df = pd.DataFrame({\n",
        "        \"Label\": class_names,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-Score\": f1,\n",
        "        \"Accuracy (%)\": (cm.diagonal() / cm.sum(axis=1)) * 100\n",
        "    })\n",
        "    print(\"ğŸ“Š Per-class metrics:\")\n",
        "    print(metrics_df.round(3))\n",
        "    metrics_df.to_csv(os.path.join(test_dir, \"test_metrics.csv\"), index=False)\n",
        "\n",
        "    # ğŸŸ¦ Confusion Matrix\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    ConfusionMatrixDisplay(cm, display_labels=class_names).plot(values_format=\".0f\", cmap=\"Blues\")\n",
        "    plt.title(\"Confusion Matrix (YOLOv11)\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(test_dir, \"confusion_matrix_yolov11.png\"))\n",
        "    plt.show()\n",
        "\n",
        "    # ğŸŸ© Metric Bars\n",
        "    for metric, color in zip([\"Precision\", \"Recall\", \"F1-Score\"], [\"mediumseagreen\", \"gold\", \"tomato\"]):\n",
        "        plt.figure(figsize=(4, 4))\n",
        "        plt.bar(class_names, metrics_df[metric], color=color)\n",
        "        plt.ylim(0, 1)\n",
        "        plt.ylabel(metric)\n",
        "        plt.title(f\"Per-Class {metric} (YOLOv11)\")\n",
        "        plt.grid(True, ls=\"--\", alpha=0.4)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(test_dir, f\"per_class_{metric.lower()}_yolov11.png\"))\n",
        "        plt.show()\n",
        "\n",
        "    # ğŸŸ¨ Accuracy\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.bar(class_names, metrics_df[\"Accuracy (%)\"], color=\"cornflowerblue\")\n",
        "    plt.ylim(0, 100)\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.title(\"Per-Class Accuracy (YOLOv11)\")\n",
        "    plt.grid(True, ls=\"--\", alpha=0.4)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(test_dir, \"per_class_accuracy_yolov11.png\"))\n",
        "    plt.show()\n",
        "\n",
        "    # ğŸŸ¦ Confidence Histogram\n",
        "    if len(conf_scores) > 0:\n",
        "        mean_conf, std_conf = np.mean(conf_scores), np.std(conf_scores)\n",
        "        plt.figure(figsize=(4, 4))\n",
        "        plt.hist(conf_scores, bins=20, color=\"skyblue\", edgecolor=\"k\")\n",
        "        plt.axvline(mean_conf, color=\"red\", ls=\"--\", label=f\"Î¼={mean_conf:.2f}\")\n",
        "        plt.legend()\n",
        "        plt.xlabel(\"Confidence\")\n",
        "        plt.ylabel(\"Frequency\")\n",
        "        plt.title(\"Confidence Distribution (YOLOv11)\")\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(test_dir, \"confidence_hist_yolov11.png\"))\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"âš ï¸ No confidence scores found â€” skipping confidence histogram.\")\n",
        "\n",
        "    # ğŸ”µ Precisionâ€“Recall Scatter\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.scatter(precision, recall, s=80, c=\"dodgerblue\")\n",
        "    for i, cls in enumerate(class_names):\n",
        "        plt.text(precision[i] + 0.01, recall[i], cls, fontsize=9)\n",
        "    plt.xlabel(\"Precision\")\n",
        "    plt.ylabel(\"Recall\")\n",
        "    plt.title(\"Precisionâ€“Recall Scatter (YOLOv11)\")\n",
        "    plt.grid(True, ls=\"--\", alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(test_dir, \"precision_recall_scatter_yolov11.png\"))\n",
        "    plt.show()\n",
        "\n",
        "    # ===============================================================\n",
        "    # ğŸ”¶ ADDITIONAL CURVES (True per-class Precision, Recall, F1)\n",
        "    # ===============================================================\n",
        "    if len(conf_scores) > 0 and len(y_true) == len(y_pred):\n",
        "        try:\n",
        "            print(\"ğŸ“ˆ Generating true per-class performance curves...\")\n",
        "            for i, cls in enumerate(class_names):\n",
        "                y_true_cls = np.array([1 if t == i else 0 for t in y_true])\n",
        "                y_score_cls = np.array([\n",
        "                    conf_scores[j] if y_pred[j] == i else 0 for j in range(len(y_pred))\n",
        "                ])\n",
        "                if y_true_cls.sum() == 0:\n",
        "                    print(f\"âš ï¸ Skipping '{cls}' â€” no true samples in test set.\")\n",
        "                    continue\n",
        "\n",
        "                prec_c, rec_c, thresh = precision_recall_curve(y_true_cls, y_score_cls)\n",
        "                f1_c = 2 * (prec_c * rec_c) / (prec_c + rec_c + 1e-6)\n",
        "                best_i = np.argmax(f1_c)\n",
        "                best_f1, best_conf = f1_c[best_i], thresh[min(best_i, len(thresh) - 1)]\n",
        "\n",
        "                # ---- F1â€“Confidence Curve ----\n",
        "                plt.figure(figsize=(4, 4))\n",
        "                plt.plot(thresh, f1_c[:-1], lw=2, color=\"blue\")\n",
        "                plt.axvline(best_conf, color=\"red\", ls=\"--\",\n",
        "                            label=f\"Best F1={best_f1:.2f} @ conf={best_conf:.2f}\")\n",
        "                plt.title(f\"{cls} â€” F1 vs Confidence\")\n",
        "                plt.xlabel(\"Confidence Threshold\")\n",
        "                plt.ylabel(\"F1-Score\")\n",
        "                plt.grid(True, ls=\"--\", alpha=0.4)\n",
        "                plt.legend()\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(os.path.join(test_dir, f\"f1_conf_curve_{cls.replace(' ', '_').lower()}.png\"))\n",
        "                plt.show()\n",
        "\n",
        "                # ---- Precisionâ€“Recall Curve ----\n",
        "                plt.figure(figsize=(4, 4))\n",
        "                plt.plot(rec_c, prec_c, lw=2, color=\"purple\")\n",
        "                plt.title(f\"{cls} â€” Precisionâ€“Recall Curve\")\n",
        "                plt.xlabel(\"Recall\")\n",
        "                plt.ylabel(\"Precision\")\n",
        "                plt.grid(True, ls=\"--\", alpha=0.4)\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(os.path.join(test_dir, f\"pr_curve_{cls.replace(' ', '_').lower()}.png\"))\n",
        "                plt.show()\n",
        "\n",
        "                # ---- Precision / Recall vs Confidence ----\n",
        "                plt.figure(figsize=(4, 4))\n",
        "                plt.plot(thresh, prec_c[:-1], lw=2, color=\"green\", label=\"Precision\")\n",
        "                plt.plot(thresh, rec_c[:-1], lw=2, color=\"orange\", label=\"Recall\")\n",
        "                plt.title(f\"{cls} â€” Precision & Recall vs Confidence\")\n",
        "                plt.xlabel(\"Confidence Threshold\")\n",
        "                plt.ylabel(\"Score\")\n",
        "                plt.legend()\n",
        "                plt.grid(True, ls=\"--\", alpha=0.4)\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(os.path.join(test_dir, f\"pr_conf_curve_{cls.replace(' ', '_').lower()}.png\"))\n",
        "                plt.show()\n",
        "\n",
        "            print(\"âœ… True per-class PR/F1 curves saved successfully.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Per-class curve plotting failed: {e}\")\n",
        "    else:\n",
        "        print(\"âš ï¸ Skipping per-class curve generation â€” missing data or mismatched lengths.\")\n",
        "\n",
        "\n",
        "def safe_visualize_results(y_true=None, y_pred=None, conf_scores=None, test_dir=None):\n",
        "    \"\"\"Wrapper to auto-load GT and find latest test folder.\"\"\"\n",
        "    if test_dir is None and 'run_dir' in globals():\n",
        "        cands = glob.glob(os.path.join(run_dir, \"**\", \"test_results\"), recursive=True)\n",
        "        test_dir = max(cands, key=os.path.getmtime) if cands else os.path.join(run_dir, \"test_results\")\n",
        "\n",
        "    if not os.path.exists(test_dir):\n",
        "        os.makedirs(test_dir, exist_ok=True)\n",
        "        print(f\"ğŸ“ Created missing test_results folder: {test_dir}\")\n",
        "\n",
        "    if y_true is None or len(y_true) == 0:\n",
        "        labels_dir = os.path.join(dataset.location, \"test\", \"labels\")\n",
        "        y_true = load_ground_truth_labels(labels_dir)\n",
        "\n",
        "    print(f\"ğŸ¨ Starting visualization for results in: {test_dir}\")\n",
        "    try:\n",
        "        visualize_test_results(y_true, y_pred, conf_scores, test_dir)\n",
        "        print(\"ğŸ¯ Visualization complete.\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Visualization failed: {e}\")\n",
        "\n",
        "\n",
        "# ğŸš€ RUN VISUALIZATION\n",
        "safe_visualize_results(y_true, y_pred, conf_scores, test_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ultralytics\n",
        "ultralytics.__version__\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FCJGmq_CXaLA",
        "outputId": "c3fdf5e0-64ee-4274-eebb-d6d8a3964520"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'8.3.228'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deiloQ-ufHfz"
      },
      "outputs": [],
      "source": [
        "# # ===============================================================\n",
        "# # # ğŸ§© BLOCK 6 â€” RELOAD & VISUALIZE SAVED RESULTS\n",
        "# # ===============================================================\n",
        "# # # This block allows visualization of previously saved training or test results\n",
        "# # # without re-running the model inference.\n",
        "\n",
        "# def reload_and_visualize(run_dir: str):\n",
        "#     \"\"\"\n",
        "#     Reload saved CSVs, metrics, and images from a past YOLO run.\n",
        "#     Generates inline plots (loss curves, mAP, PR, confusion matrix, etc.)\n",
        "#     \"\"\"\n",
        "#     print(f\"ğŸ“‚ Reloading results from: {run_dir}\")\n",
        "#     result_csv = os.path.join(run_dir, \"results.csv\")\n",
        "#     summary_csv = os.path.join(run_dir, \"summary_metrics.csv\")\n",
        "#     test_dir = os.path.join(run_dir, \"test_results\")\n",
        "\n",
        "#     # 1ï¸âƒ£ Summary Metrics\n",
        "#     if os.path.exists(summary_csv):\n",
        "#         print(\"\\nâœ… Summary Metrics (Final Epoch):\")\n",
        "#         df_summary = pd.read_csv(summary_csv)\n",
        "#         display(df_summary.style.background_gradient(cmap=\"YlGnBu\").format(precision=3))\n",
        "#     else:\n",
        "#         print(\"âš ï¸ No summary_metrics.csv found.\")\n",
        "\n",
        "#     # 2ï¸âƒ£ Training Curves\n",
        "#     if os.path.exists(result_csv):\n",
        "#         df = pd.read_csv(result_csv)\n",
        "#         print(\"\\nğŸ“ˆ Training & Validation Loss Curves:\")\n",
        "#         plt.figure(figsize=(12, 5))\n",
        "#         plt.plot(df[\"epoch\"], df[\"train/box_loss\"], label=\"Train Box Loss\")\n",
        "#         plt.plot(df[\"epoch\"], df[\"train/cls_loss\"], label=\"Train Class Loss\")\n",
        "#         if \"val/box_loss\" in df.columns:\n",
        "#             plt.plot(df[\"epoch\"], df[\"val/box_loss\"], \"--\", label=\"Val Box Loss\")\n",
        "#         plt.xlabel(\"Epoch\")\n",
        "#         plt.ylabel(\"Loss\")\n",
        "#         plt.title(\"Training & Validation Loss\")\n",
        "#         plt.legend()\n",
        "#         plt.grid(True)\n",
        "#         plt.show()\n",
        "\n",
        "#         if \"metrics/mAP50(B)\" in df.columns:\n",
        "#             print(\"\\nğŸ¯ mAP Progress:\")\n",
        "#             plt.figure(figsize=(8, 4))\n",
        "#             plt.plot(df[\"epoch\"], df[\"metrics/mAP50(B)\"], label=\"mAP@0.5\")\n",
        "#             plt.plot(df[\"epoch\"], df[\"metrics/mAP50-95(B)\"], label=\"mAP@0.5:0.95\")\n",
        "#             plt.xlabel(\"Epoch\")\n",
        "#             plt.ylabel(\"mAP\")\n",
        "#             plt.legend()\n",
        "#             plt.grid(True)\n",
        "#             plt.show()\n",
        "#     else:\n",
        "#         print(\"âš ï¸ results.csv not found in this run.\")\n",
        "\n",
        "#     # 3ï¸âƒ£ Precisionâ€“Recall and Confidence Curves (auto-display if present)\n",
        "#     curve_imgs = glob.glob(os.path.join(run_dir, \"*curve*.png\"))\n",
        "#     if curve_imgs:\n",
        "#         print(\"\\nğŸ“Š Precisionâ€“Recall and Confidence Curves:\")\n",
        "#         for img_path in curve_imgs:\n",
        "#             img = plt.imread(img_path)\n",
        "#             plt.figure(figsize=(6, 4))\n",
        "#             plt.imshow(img)\n",
        "#             plt.axis(\"off\")\n",
        "#             plt.title(os.path.basename(img_path))\n",
        "#             plt.show()\n",
        "#     else:\n",
        "#         print(\"âš ï¸ No PR/Confidence curve images found.\")\n",
        "\n",
        "#     # 4ï¸âƒ£ Test Results (if available)\n",
        "#     if os.path.exists(test_dir):\n",
        "#         print(\"\\nğŸ§ª Test Results Summary:\")\n",
        "#         test_metrics = os.path.join(test_dir, \"test_metrics.csv\")\n",
        "#         if os.path.exists(test_metrics):\n",
        "#             df_test = pd.read_csv(test_metrics)\n",
        "#             display(df_test.style.background_gradient(cmap=\"YlOrBr\").format(precision=3))\n",
        "#         else:\n",
        "#             print(\"âš ï¸ test_metrics.csv not found in test_results.\")\n",
        "\n",
        "#         # Confusion Matrix + Per-Class Accuracy + Confidence Hist\n",
        "#         img_files = glob.glob(os.path.join(test_dir, \"*.png\"))\n",
        "#         if img_files:\n",
        "#             print(\"\\nğŸ–¼ï¸ Saved Graphs from Test Results:\")\n",
        "#             for img_path in img_files:\n",
        "#                 img = plt.imread(img_path)\n",
        "#                 plt.figure(figsize=(6, 5))\n",
        "#                 plt.imshow(img)\n",
        "#                 plt.axis(\"off\")\n",
        "#                 plt.title(os.path.basename(img_path))\n",
        "#                 plt.show()\n",
        "#         else:\n",
        "#             print(\"âš ï¸ No saved graphs found in test_results folder.\")\n",
        "#     else:\n",
        "#         print(\"âš ï¸ No test_results directory found in this run.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOtCmuG8YTgruvGfDj/6nJ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}