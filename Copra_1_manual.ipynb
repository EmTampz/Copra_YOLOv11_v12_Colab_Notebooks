{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8pCziy6DcxE7G+1q9bO/K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmTampz/Copra_YOLOv11_v12_Colab_Notebooks/blob/main/Copra_1_manual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgHH8hftgVWy",
        "outputId": "f9c7d85e-a752-474c-8972-e09f04f37731",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.223-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.223-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.223 ultralytics-thop-2.0.18\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.9)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.11-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.10.5)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Collecting pi-heif<2 (from roboflow)\n",
            "  Downloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.60.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.4)\n",
            "Downloading roboflow-1.2.11-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.1 pillow-avif-plugin-1.5.2 roboflow-1.2.11\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# ðŸ“¦ ENVIRONMENT SETUP for YOLOv11 Thesis (Colab)\n",
        "# ==========================================================\n",
        "# This installs only what is required for:\n",
        "# - YOLOv11 object detection, classification, segmentation\n",
        "# - Grid search tuning and visualization\n",
        "# - Logging and performance tracking\n",
        "# ==========================================================\n",
        "\n",
        "# Core deep learning and YOLO library\n",
        "!pip install -U ultralytics\n",
        "\n",
        "# Core data handling, visualization, and ML utilities\n",
        "!pip install pandas matplotlib seaborn pillow scikit-learn\n",
        "\n",
        "# Optional (but recommended) for monitoring and logging\n",
        "!pip install tensorboard tqdm\n",
        "\n",
        "# Example Roboflow integration\n",
        "!pip install roboflow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, ultralytics, pandas as pd, matplotlib, seaborn, PIL, sklearn, tqdm, tensorboard\n",
        "\n",
        "print(f\"PyTorch version : {torch.__version__}\")\n",
        "print(f\"CUDA available  : {torch.cuda.is_available()}\")\n",
        "print(f\"Ultralytics ver : {ultralytics.__version__}\")\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEYK9F_5ktKg",
        "outputId": "aa8ac21b-82de-466c-ce06-062aafb7424e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.223 ðŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 39.3/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "manual_tuning_yolo11.py\n",
        "Manual hyperparameter tuning for YOLOv11 (Detection -> Segmentation -> Classification)\n",
        "Integrated with Roboflow API for automatic dataset download (YOLO format).\n",
        "Runs on Google Colab GPU with TensorBoard logging, timestamps, CSV results,\n",
        "limited inference visualization for quick inspection, and side-by-side comparison.\n",
        "Automatically zips all inference results for download.\n",
        "\n",
        "Before running:\n",
        "!pip install ultralytics pandas matplotlib seaborn pillow roboflow\n",
        "\"\"\"\n",
        "\n",
        "import os, time, shutil, yaml, json, random, glob, zipfile\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from itertools import product\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n",
        "\n",
        "from roboflow import Roboflow\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Image as IPyImage, display   # âœ… for inline visualization in Colab\n",
        "\n",
        "# ---------------- USER CONFIG ----------------\n",
        "# âœ… Roboflow integration â€” replace with your API key and dataset details\n",
        "rf = Roboflow(api_key=\"LS1Ohi2OQZ178OOqQ4zc\")\n",
        "project = rf.workspace(\"cv-opfhv\").project(\"mor-v4-8itha\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov11\")\n",
        "\n",
        "# Dynamically detect the dataset YAML path\n",
        "ROBOFLOW_DATA_YAML = os.path.join(dataset.location, \"data.yaml\")\n",
        "print(f\"âœ… Dataset successfully downloaded from Roboflow!\\nðŸ“‚ YAML path: {ROBOFLOW_DATA_YAML}\")\n",
        "\n",
        "RESULTS_BASE = \"/content/copra_yolo11_manual_results\"\n",
        "os.makedirs(RESULTS_BASE, exist_ok=True)\n",
        "\n",
        "# # Tasks: Detection â†’ Segmentation â†’ Classification\n",
        "TASKS = [\"detect\", \"seg\", \"cls\"]\n",
        "MODEL_MAP = {\n",
        "    \"detect\": \"yolo11n.pt\",\n",
        "    \"seg\":    \"yolo11n-seg.pt\",\n",
        "    \"cls\":    \"yolo11n-cls.pt\"\n",
        "}\n",
        "\n",
        "# # Manual hyperparameters\n",
        "MANUAL_CONFIG = {\n",
        "    \"epochs\": 100,\n",
        "    \"batch\": 16,\n",
        "    \"optimizer\": \"auto\",\n",
        "    \"lr0\": 0.001,\n",
        "    \"patience\": 100\n",
        "}\n",
        "\n",
        "IMG_SIZE = 640\n",
        "TENSORBOARD_ENABLE = True\n",
        "\n",
        "# CSV to append results\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "SUMMARY_CSV = os.path.join(RESULTS_BASE, f\"manual_summary_{TIMESTAMP}.csv\")\n",
        "\n",
        "# ---------------- Helper utilities ----------------\n",
        "def load_data_yaml(path):\n",
        "    with open(path, \"r\") as f:\n",
        "        return yaml.safe_load(f)\n",
        "\n",
        "# Compute IoU between predicted and actual bounding boxes used for Evaluating detection accuracy, computing mAP\n",
        "def iou_xyxy(box1, box2):\n",
        "    x1 = max(box1[0], box2[0]); y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2]); y2 = min(box1[3], box2[3])\n",
        "    inter_w = max(0, x2 - x1); inter_h = max(0, y2 - y1)\n",
        "    inter_area = inter_w * inter_h\n",
        "    area1 = max(0, (box1[2] - box1[0]) * (box1[3] - box1[1]))\n",
        "    area2 = max(0, (box2[2] - box2[0]) * (box2[3] - box2[1]))\n",
        "    union = area1 + area2 - inter_area\n",
        "    return inter_area / union if union > 0 else 0.0\n",
        "\n",
        "# Convert normalized YOLO coordinates to pixel coordinates, Preparing data for IoU computation, visualization\n",
        "def yolo_label_to_xyxy(norm, w, h):\n",
        "    xc, yc, bw, bh = norm\n",
        "    xc *= w; yc *= h; bw *= w; bh *= h\n",
        "    x1 = xc - bw/2; y1 = yc - bh/2; x2 = xc + bw/2; y2 = yc + bh/2\n",
        "    return [x1, y1, x2, y2]\n",
        "\n",
        "# Reads YOLO label files and returns structured annotations, Dataset quality checks, IoU computation\n",
        "def parse_label_file(label_path):\n",
        "    labels = []\n",
        "    if not os.path.exists(label_path):\n",
        "        return labels\n",
        "    with open(label_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 5:\n",
        "                cls = int(parts[0]); norm = list(map(float, parts[1:5]))\n",
        "                labels.append((cls, norm))\n",
        "    return labels\n",
        "\n",
        "# Automatically enables TensorBoard for Live training visualization\n",
        "def ensure_tensorboard():\n",
        "    if TENSORBOARD_ENABLE:\n",
        "        os.system(\"yolo settings tensorboard=True\")\n",
        "\n",
        "# Copies trained .pt model with run details\n",
        "def save_weights_copy(src_path, dest_dir, run_name):\n",
        "    os.makedirs(dest_dir, exist_ok=True)\n",
        "    if src_path and os.path.exists(src_path):\n",
        "        dest = os.path.join(dest_dir, f\"{run_name}_{Path(src_path).name}\")\n",
        "        shutil.copy(src_path, dest)\n",
        "        return dest\n",
        "    return None\n",
        "\n",
        "# ---------------- Main per-task run ----------------\n",
        "def run_one_task(task, base_model, cfg, results_base):\n",
        "    assert task in MODEL_MAP\n",
        "    model = YOLO(base_model)\n",
        "    run_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    run_name = f\"{task}_manual_e{cfg['epochs']}_b{cfg['batch']}_p{cfg['patience']}_opt{cfg['optimizer']}_lr{cfg['lr0']}_{run_timestamp}\"\n",
        "    project_dir = os.path.join(results_base, task, run_name)\n",
        "    os.makedirs(project_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"\\n--- Training {task} | run: {run_name} ---\")\n",
        "    t0 = time.time()\n",
        "    # Start training\n",
        "    model.train(\n",
        "        data=ROBOFLOW_DATA_YAML,\n",
        "        epochs=cfg[\"epochs\"],\n",
        "        batch=cfg[\"batch\"],\n",
        "        imgsz=IMG_SIZE,\n",
        "        optimizer=cfg[\"optimizer\"],\n",
        "        lr0=cfg[\"lr0\"],\n",
        "        patience=cfg[\"patience\"],\n",
        "        project=os.path.join(results_base, task),\n",
        "        name=run_name,\n",
        "        resume=False\n",
        "    )\n",
        "    t1 = time.time()\n",
        "    elapsed = round(t1 - t0, 2)\n",
        "    print(f\"â±ï¸ Training finished in {elapsed} seconds\")\n",
        "\n",
        "    # Find best or last weight produced by Ultralytics\n",
        "    weights_dir = os.path.join(results_base, task, run_name, \"weights\")\n",
        "    best_w = os.path.join(weights_dir, \"best.pt\")\n",
        "    last_w = os.path.join(weights_dir, \"last.pt\")\n",
        "    chosen = best_w if os.path.exists(best_w) else (last_w if os.path.exists(last_w) else None)\n",
        "    saved_copy = save_weights_copy(chosen, os.path.join(results_base, \"saved_models\"), run_name)\n",
        "\n",
        "    # Validate and extract metrics\n",
        "    val_results = model.val()\n",
        "    metrics = {}\n",
        "    try:\n",
        "        metrics[\"mAP@0.5\"] = float(val_results.box.map50)\n",
        "        metrics[\"mAP@0.5:0.95\"] = float(val_results.box.map)\n",
        "        metrics[\"precision\"] = float(val_results.box.precision)\n",
        "        metrics[\"recall\"] = float(val_results.box.recall)\n",
        "        metrics[\"f1\"] = float(val_results.box.f1)\n",
        "    except Exception:\n",
        "        metrics = {\"mAP@0.5\": None, \"mAP@0.5:0.95\": None, \"precision\": None, \"recall\": None, \"f1\": None}\n",
        "\n",
        "    # Quick inference for visualization (limited to 3 images)\n",
        "    infer_folder = os.path.join(project_dir, \"inference_results\")\n",
        "    os.makedirs(infer_folder, exist_ok=True)\n",
        "    val_images_path = os.path.join(dataset.location, \"valid\", \"images\")\n",
        "    sample_imgs = random.sample(glob.glob(f\"{val_images_path}/*.jpg\"), min(3, len(glob.glob(f\"{val_images_path}/*.jpg\"))))\n",
        "\n",
        "    if sample_imgs:\n",
        "        print(f\"ðŸ–¼ï¸ Running quick inference on {len(sample_imgs)} sample images...\")\n",
        "        model.predict(source=sample_imgs, save=True, project=infer_folder, name=\"sample_preds\")\n",
        "        pred_folder = os.path.join(infer_folder, \"sample_preds\")\n",
        "        for img in glob.glob(f\"{pred_folder}/*.jpg\")[:3]:\n",
        "            display(IPyImage(filename=img, width=600))  # Display few predictions only\n",
        "            print(f\"Displayed: {os.path.basename(img)}\")\n",
        "\n",
        "    # ---------------- Per-class metrics and plots ----------------\n",
        "    data_meta = load_data_yaml(ROBOFLOW_DATA_YAML)\n",
        "    class_names = data_meta.get(\"names\", [])\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    # Prepare per-class metrics on validation set\n",
        "    val_images_dir = os.path.join(dataset.location, \"valid\", \"images\")\n",
        "    for img_path in glob.glob(f\"{val_images_dir}/*.jpg\"):\n",
        "        # YOLO prediction\n",
        "        res_list = model.predict(img_path, imgsz=IMG_SIZE, conf=0.25, iou=0.45, stream=False)\n",
        "        if len(res_list) == 0: continue\n",
        "        res = res_list[0]\n",
        "        preds = []\n",
        "        if hasattr(res, \"boxes\") and res.boxes.data is not None:\n",
        "            for b in res.boxes.data.tolist():\n",
        "                x1, y1, x2, y2, score, cls = b\n",
        "                preds.append({\"box\":[x1, y1, x2, y2], \"cls\": int(cls)})\n",
        "\n",
        "        # Ground truth\n",
        "        label_path = Path(img_path).with_suffix(\".txt\")\n",
        "        if not label_path.exists():\n",
        "            alt = Path(val_images_dir).parent / \"labels\" / label_path.name\n",
        "            if alt.exists(): label_path = alt\n",
        "        gt = parse_label_file(str(label_path))\n",
        "        gt_bboxes = []\n",
        "        try:\n",
        "            w,h = Image.open(img_path).size\n",
        "        except:\n",
        "            w,h = IMG_SIZE, IMG_SIZE\n",
        "        for cid,norm in gt:\n",
        "            bb = yolo_label_to_xyxy(norm, w, h)\n",
        "            gt_bboxes.append({\"box\": bb, \"cls\": cid})\n",
        "\n",
        "        # Match preds to GT\n",
        "        used = set()\n",
        "        for p in preds:\n",
        "            best_iou = 0; best_idx = -1\n",
        "            for i, g in enumerate(gt_bboxes):\n",
        "                if i in used: continue\n",
        "                iou = iou_xyxy(p[\"box\"], g[\"box\"])\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou; best_idx = i\n",
        "            if best_iou >= 0.5 and best_idx >= 0:\n",
        "                used.add(best_idx)\n",
        "                y_true.append(gt_bboxes[best_idx][\"cls\"])\n",
        "                y_pred.append(p[\"cls\"])\n",
        "            else:\n",
        "                y_true.append(-1)\n",
        "                y_pred.append(p[\"cls\"])\n",
        "        # Add unmatched GTs\n",
        "        for i, g in enumerate(gt_bboxes):\n",
        "            if i not in used:\n",
        "                y_true.append(g[\"cls\"])\n",
        "                y_pred.append(-1)\n",
        "\n",
        "    # Compute per-class metrics\n",
        "    if len(y_true) > 0:\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "            y_true, y_pred, labels=list(range(len(class_names))), zero_division=0\n",
        "        )\n",
        "        per_class_df = pd.DataFrame({\n",
        "            \"class\": class_names,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"f1\": f1\n",
        "        })\n",
        "        per_class_csv = os.path.join(project_dir, \"per_class_metrics.csv\")\n",
        "        per_class_df.to_csv(per_class_csv, index=False)\n",
        "        # Plot per-class metrics\n",
        "        fig, ax = plt.subplots(figsize=(10,5))\n",
        "        x = np.arange(len(class_names))\n",
        "        ax.bar(x - 0.2, precision, width=0.2, label=\"Precision\")\n",
        "        ax.bar(x, recall, width=0.2, label=\"Recall\")\n",
        "        ax.bar(x + 0.2, f1, width=0.2, label=\"F1-score\")\n",
        "        ax.set_xticks(x); ax.set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
        "        ax.set_ylabel(\"Score\")\n",
        "        ax.set_title(f\"Per-class Precision, Recall, F1 for {run_name}\")\n",
        "        ax.legend()\n",
        "        plt.tight_layout()\n",
        "        per_class_png = os.path.join(project_dir, \"per_class_metrics.png\")\n",
        "        plt.savefig(per_class_png)\n",
        "        plt.close()\n",
        "\n",
        "    # Save record\n",
        "    run_record = {\n",
        "        \"timestamp\": run_timestamp,\n",
        "        \"task\": task,\n",
        "        \"run_name\": run_name,\n",
        "        \"model_source\": base_model,\n",
        "        \"saved_model\": saved_copy,\n",
        "        \"epochs\": cfg[\"epochs\"],\n",
        "        \"batch\": cfg[\"batch\"],\n",
        "        \"optimizer\": cfg[\"optimizer\"],\n",
        "        \"lr0\": cfg[\"lr0\"],\n",
        "        \"patience\": cfg[\"patience\"],\n",
        "        \"elapsed_seconds\": elapsed,\n",
        "        \"mAP@0.5\": metrics.get(\"mAP@0.5\"),\n",
        "        \"mAP@0.5:0.95\": metrics.get(\"mAP@0.5:0.95\"),\n",
        "        \"precision\": metrics.get(\"precision\"),\n",
        "        \"recall\": metrics.get(\"recall\"),\n",
        "        \"f1\": metrics.get(\"f1\"),\n",
        "        \"inference_folder\": infer_folder,\n",
        "        \"per_class_metrics_csv\": per_class_csv,\n",
        "        \"per_class_metrics_png\": per_class_png\n",
        "    }\n",
        "    return run_record\n",
        "\n",
        "# ---------------- Zip everything ----------------\n",
        "def zip_all_results(results_base, timestamp):\n",
        "    zip_name = os.path.join(results_base, f\"all_results_{timestamp}.zip\")\n",
        "    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, _, files in os.walk(results_base):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, start=results_base)\n",
        "                zipf.write(file_path, arcname)\n",
        "    print(f\"\\nðŸ“¦ All results (weights, CSVs, plots, inference) zipped: {zip_name}\")\n",
        "    return zip_name\n",
        "\n",
        "# ---------------- Entry point ----------------\n",
        "if __name__ == \"__main__\":\n",
        "    ensure_tensorboard()\n",
        "    data_meta = load_data_yaml(ROBOFLOW_DATA_YAML)\n",
        "    print(\"ðŸ“Š Classes:\", data_meta.get(\"names\"))\n",
        "    summary_rows = []\n",
        "\n",
        "    for task in TASKS:\n",
        "        base_model = MODEL_MAP[task]\n",
        "        rec = run_one_task(task, base_model, MANUAL_CONFIG, RESULTS_BASE)\n",
        "        print(\"Run summary:\", rec)\n",
        "        summary_rows.append(rec)\n",
        "\n",
        "    # Save summary CSV\n",
        "    df = pd.DataFrame(summary_rows)\n",
        "    df.to_csv(SUMMARY_CSV, index=False)\n",
        "    print(f\"\\nâœ… Manual tuning complete. Summary saved to: {SUMMARY_CSV}\")\n",
        "    print(\"ðŸ“‚ Saved models and TensorBoard logs are in:\", RESULTS_BASE)\n",
        "\n",
        "    # Zip everything\n",
        "    zip_all_results(RESULTS_BASE, TIMESTAMP)\n"
      ],
      "metadata": {
        "id": "1TGBzEMtk8yU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}